{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474c28b0-0e0c-4c9e-a7ee-15d840491522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8537f1-2d30-406f-8a30-f03332b14a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_SIZE = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "DATA_URL = 'https://raw.githubusercontent.com/tonylaioffer/stock-prediction-lstm-using-keras/master/data/sandp500/all_stocks_5yr.csv'\n",
    "COMPANY_NAME = 'SWKS'\n",
    "LAG = 7\n",
    "EPOCHS = 150\n",
    "LR = 1e-3\n",
    "NO_CUDA = False\n",
    "SEED = 42\n",
    "LOG_PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28f1f5-8339-4e43-a84a-28bdbe31cc25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8507ed1a-6619-453c-800d-0ec6265bb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_distribute():\n",
    "    return dist.is_available() and WORLD_SIZE > 1\n",
    "\n",
    "\n",
    "def is_distributed():\n",
    "    return dist.is_available() and dist.is_initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a189d-0dc5-485f-aab3-1ca7e7b0e0d4",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fddcb2-6a26-49e4-a191-4170523130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name, url=DATA_URL):\n",
    "    df = pd.read_csv(url)\n",
    "    df = df[df['Name'] == name]\n",
    "    close_price = df.close.values.reshape(-1, 1)\n",
    "#     close_price = df.iloc[:, 1:6].values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    close_price = scaler.fit_transform(close_price).squeeze() # Scale the data\n",
    "\n",
    "    return close_price, scaler\n",
    "\n",
    "\n",
    "def process_data(data, lag):\n",
    "    X, Y = [], []\n",
    "    lag = lag\n",
    "    for i in range(len(data) - lag - 1):\n",
    "        X.append(data[i: (i + lag)])\n",
    "        Y.append(data[(i + lag)])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y, train=True, test_size=0.2):\n",
    "        super(StockDataset, self).__init__()\n",
    "        cutoff = int((1-test_size) * len(X))\n",
    "        if train:\n",
    "            self.features = X[:cutoff]\n",
    "            self.targets = y[:cutoff]\n",
    "        else:\n",
    "            self.features = X[cutoff:]\n",
    "            self.targets = y[cutoff:]\n",
    "\n",
    "        self.features = np.expand_dims(self.features, axis=1).astype(np.float32)\n",
    "        self.targets = self.targets.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.features) == len(self.targets)\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.features[item], self.targets[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b3daa-82f5-407d-b802-410be76a1f4d",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d358042a-9942-4ee4-a266-cec7c1458870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, i_size, h_size, n_layers, o_size, dropout=0.1, bidirectional=True):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_directions = bidirectional + 1\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=i_size,\n",
    "            hidden_size=h_size,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.out = nn.Linear(h_size, o_size)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        r_out, hidden_state = self.rnn(x, h_state)\n",
    "\n",
    "        hidden_size = hidden_state[-1].size(-1)\n",
    "        r_out = r_out.view(-1, self.num_directions, hidden_size)\n",
    "        outs = self.out(r_out)\n",
    "\n",
    "        return outs, hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7293a-d753-4d69-a672-bc7357017b20",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7773e5a-3853-4d85-a8d7-36a59c26d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    for features, targets in train_loader:\n",
    "        features, targets = features.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(features, None)\n",
    "        loss = loss_fn(output.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    msg = \"Train Epoch: {}\\tloss={}\".format(\n",
    "        epoch, loss.item())\n",
    "    logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4884b-0124-4863-ad64-61db43733704",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd19f607-13bf-45e1-8a7f-47a9f4636615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, loss_fn, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, targets in test_loader:\n",
    "            features, targets = features.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "            output, _ = model(features, None)\n",
    "            test_loss = loss_fn(output.squeeze(), targets)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        logging.info(\"{{metricName: loss, metricValue: {}}}\\n\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612d9b7-66d4-4cef-9455-c05474c1f334",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da038f36-30f0-449e-aa98-71b335940fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if dist.is_available():\n",
    "        BACKEND = dist.Backend.GLOO\n",
    "\n",
    "    # Use this format (%Y-%m-%dT%H:%M:%SZ) to record timestamp of the metrics.\n",
    "    # If log_path is empty print log to StdOut, otherwise print log to the file.\n",
    "    if LOG_PATH == \"\":\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "            datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "            level=logging.DEBUG)\n",
    "    else:\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "            datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "            level=logging.DEBUG,\n",
    "            filename=LOG_PATH)\n",
    "\n",
    "    use_cuda = not NO_CUDA and torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if should_distribute():\n",
    "        print(\"Using distributed PyTorch with {} backend\".format(BACKEND))\n",
    "        dist.init_process_group(backend=BACKEND)\n",
    "\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "\n",
    "    data, scaler = get_data(name=COMPANY_NAME)\n",
    "    X, y = process_data(data, LAG)\n",
    "\n",
    "    train_dset = StockDataset(X, y, train=True)\n",
    "    test_dset = StockDataset(X, y, train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dset,\n",
    "                              batch_size=len(train_dset),\n",
    "                              shuffle=True,\n",
    "                              **kwargs\n",
    "                              )\n",
    "\n",
    "    test_loader = DataLoader(test_dset,\n",
    "                             batch_size=len(test_dset),\n",
    "                             shuffle=True,\n",
    "                             **kwargs,\n",
    "                            )\n",
    "\n",
    "    model = RNN(i_size=LAG,\n",
    "                h_size=64,\n",
    "                n_layers=3,\n",
    "                o_size=1,\n",
    "                bidirectional=False,\n",
    "                )\n",
    "    model.to(device)\n",
    "\n",
    "    if is_distributed():\n",
    "        Distributor = nn.parallel.DistributedDataParallel if use_cuda \\\n",
    "            else nn.parallel.DistributedDataParallelCPU\n",
    "        model = Distributor(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, device, train_loader, optimizer, loss_fn, epoch)\n",
    "        test(model, device, test_loader, loss_fn, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52913fec-c189-4b9e-889b-79243d3f5c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26T14:49:27Z INFO     Train Epoch: 1\tloss=0.23045894503593445\n",
      "2021-10-26T14:49:28Z INFO     Train Epoch: 2\tloss=0.20813706517219543\n",
      "2021-10-26T14:49:29Z INFO     Train Epoch: 3\tloss=0.18792681396007538\n",
      "2021-10-26T14:49:29Z INFO     Train Epoch: 4\tloss=0.1692219227552414\n",
      "2021-10-26T14:49:30Z INFO     Train Epoch: 5\tloss=0.1508132517337799\n",
      "2021-10-26T14:49:31Z INFO     Train Epoch: 6\tloss=0.13354389369487762\n",
      "2021-10-26T14:49:33Z INFO     Train Epoch: 7\tloss=0.11645235121250153\n",
      "2021-10-26T14:49:34Z INFO     Train Epoch: 8\tloss=0.1007850244641304\n",
      "2021-10-26T14:49:35Z INFO     Train Epoch: 9\tloss=0.08590594679117203\n",
      "2021-10-26T14:49:36Z INFO     Train Epoch: 10\tloss=0.07499672472476959\n",
      "2021-10-26T14:49:37Z INFO     Train Epoch: 11\tloss=0.0711047500371933\n",
      "2021-10-26T14:49:37Z INFO     Train Epoch: 12\tloss=0.07774487137794495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_z/rq45m8gs31sd_zmgzhxkyc_00000gn/T/ipykernel_60492/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_z/rq45m8gs31sd_zmgzhxkyc_00000gn/T/ipykernel_60492/1939187707.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_z/rq45m8gs31sd_zmgzhxkyc_00000gn/T/ipykernel_60492/3565107271.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, loss_fn, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67811cc-5cec-4605-a72c-8a00db9ad92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dist.is_available():\n",
    "    BACKEND = dist.Backend.GLOO\n",
    "\n",
    "# Use this format (%Y-%m-%dT%H:%M:%SZ) to record timestamp of the metrics.\n",
    "# If log_path is empty print log to StdOut, otherwise print log to the file.\n",
    "if LOG_PATH == \"\":\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "        level=logging.DEBUG)\n",
    "else:\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "        level=logging.DEBUG,\n",
    "        filename=LOG_PATH)\n",
    "\n",
    "use_cuda = not NO_CUDA and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "if should_distribute():\n",
    "    print(\"Using distributed PyTorch with {} backend\".format(BACKEND))\n",
    "    dist.init_process_group(backend=BACKEND)\n",
    "\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "\n",
    "data = get_data(name=COMPANY_NAME)\n",
    "X, y = process_data(data, LAG)\n",
    "\n",
    "train_dset = StockDataset(X, y, train=True)\n",
    "test_dset = StockDataset(X, y, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dset,\n",
    "                          batch_size=len(train_dset),\n",
    "                          shuffle=True,\n",
    "                          **kwargs\n",
    "                          )\n",
    "\n",
    "test_loader = DataLoader(test_dset,\n",
    "                         batch_size=len(test_dset),\n",
    "                         shuffle=True,\n",
    "                         **kwargs,\n",
    "                        )\n",
    "\n",
    "model = RNN(i_size=LAG,\n",
    "            h_size=64,\n",
    "            n_layers=3,\n",
    "            o_size=1,\n",
    "            bidirectional=False,\n",
    "            )\n",
    "model.to(device)\n",
    "\n",
    "if is_distributed():\n",
    "    Distributor = nn.parallel.DistributedDataParallel if use_cuda \\\n",
    "        else nn.parallel.DistributedDataParallelCPU\n",
    "    model = Distributor(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, device, train_loader, optimizer, loss_fn, epoch)\n",
    "    test(model, device, test_loader, loss_fn, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d70060-6a73-4c75-94c6-fb346563c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, targets in test_loader:\n",
    "    hidden = None\n",
    "    model.eval()\n",
    "    out, _ = model(features, hidden)\n",
    "    out = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ca1bb-3cb6-4bbf-9fa5-8e7dadf79d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(scaler.inverse_transform(targets.reshape(-1, 1)))\n",
    "plt.plot(scaler.inverse_transform(out.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70683b-f173-4b69-a2da-3977e4dca0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
